% CU CS5525
% Fall 2012
% Python Compiler
%
% report.tex
% Semester Project Report
%
% Repository:
%    https://github.com/asayler/CU-CS5525-PythonCompiler
%
% By :
%    Anne Gatchell
%       http://annegatchell.com/
%    Andy Sayler
%       http://www.andysayler.com
%    Michael (Mike) Vitousek
%       http://csel.cs.colorado.edu/~mivi2269/

\documentclass[11pt,twocolumn]{article}

\usepackage[text={6.5in, 9in}, centering]{geometry}
\usepackage{graphicx}
\usepackage{url}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{biblatex}
\usepackage{amssymb}
\bibliography{refs}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\lstset{
  language={},
  basicstyle=\footnotesize,
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=4,
  captionpos=b,
  breaklines=true,
  breakatwhitespace=false,
  frame=single,
  frameround=tttt
}

\lstdefinelanguage{llvm}{
  morecomment = [l]{;},
  morestring=[b]'', 
  sensitive = true,
  classoffset=0,
  morekeywords={
    define, declare, global, constant,
    internal, external, private,
    linkonce, linkonce_odr, weak, weak_odr, appending,
    common, extern_weak,
    thread_local, dllimport, dllexport,
    hidden, protected, default,
    except, deplibs,
    volatile, fastcc, coldcc, cc, ccc,
    x86_stdcallcc, x86_fastcallcc,
    ptx_kernel, ptx_device,
    signext, zeroext, inreg, sret, nounwind, noreturn,
    nocapture, byval, nest, readnone, readonly, noalias, uwtable,
    inlinehint, noinline, alwaysinline, optsize, ssp, sspreq,
    noredzone, noimplicitfloat, naked, alignstack,
    module, asm, align, tail, to,
    addrspace, section, alias, sideeffect, c, gc,
    target, datalayout, triple,
    blockaddress
  },
  classoffset=1,
  morekeywords={
    fadd, sub, fsub, mul, fmul,
    sdiv, udiv, fdiv, srem, urem, frem,
    and, or, xor,
    icmp, fcmp,
    eq, ne, ugt, uge, ult, ule, sgt, sge, slt, sle,
    oeq, ogt, oge, olt, ole, one, ord, ueq, ugt, uge,
    ult, ule, une, uno,
    nuw, nsw, exact, inbounds,
    phi, call, select, shl, lshr, ashr, va_arg,
    trunc, zext, sext,
    fptrunc, fpext, fptoui, fptosi, uitofp, sitofp,
    ptrtoint, inttoptr, bitcast,
    ret, br, indirectbr, switch, invoke, unwind, unreachable,
    malloc, alloca, free, load, store, getelementptr,
    extractelement, insertelement, shufflevector,
    extractvalue, insertvalue,
  },
  alsoletter={\%},
  keywordsprefix={\%},
}

\newenvironment{packed_enum}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}

\newenvironment{packed_item}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\newenvironment{packed_desc}{
\begin{description}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{description}}

\begin{document}

\title{
  Building a LLVM Python Compiler
}

\author{
  Anne Gatchell    \\ \texttt{anne.gatchell@colorado.edu} \and
  Andy Sayler      \\ \texttt{andrew.sayler@colorado.edu} \and
  Michael Vitousek \\ \texttt{michael.vitousek@colorado.edu}
}

\date{\today}

\maketitle

\begin{abstract}

We discuss the expansion of our P3 compiler to target LLVM intermediate
language assembly code. This involves the converting our intermediate
AST to SSA form as well as replacing the instruction selection
components of the existing compiler. We compare the performance and
flexibility of directly targeted x86 code vs targeting LLVM IR code.

\end{abstract}

\section{Problem Statement}

While the existing HW6, p3-compliant compiler supports 32-bit, x86
code generation, it does not support generating code for the variety
of non-x86 architectures and assembly languages common today (x64,
ARM, etc). While we could remedy this deficiency by adding additional
native code generation for non-x86 architectures directly to our
compiler, this approach would duplicate a wide range of existing
effort and would require continued maintenance to support new
architectures and assembly languages as they arise. From a software
engineering perspective, such an attempt would also increase the
likelihood bugs and errors due to the expanded code base and much
larger required breadth of expertise in a variety of assembly
languages.

Instead, we aim to leverage the existing work done by the LLVM project
\cite{llvm.org} to convert our HW6 compiler from an x86-targeted
compiler to an LLVM-targeted compiler. This will not only be efficient
from a maintenance standpoint, but it will also be a useful
introduction to a modern, commonly used compiler intermediate
language. We will maintain the current x86 targeting and add LLVM IR
Assembly \cite{lattner-llvmlangref} as an additional targeting
option. In this way, we will be able to compare our natively generated
x86 code with the LLVM-assembler generated x86 code. We will also be
able to experiment with compiling our LLVM byte-code files to assembly
languages other than x86 such as x64 and ARM.

LLVM is quickly becoming the de facto standard target for most modern
compilers for high level languages.  It provides multi-platform
support, multi-runtype support (compiled, interpreted, JIT compiled,
etc), and access to a range of existing optimization tools and
techniques. Through this project, we hope to become familiar with the
LLVM Assembly Language and LLVM system architecture while gaining
insight into the benefits of building an LLVM-targeted compiler.

\section{Background}

The primary change to our existing compiler code base is the addition
of an LLVM output target option. We discuss LLVM and its prerequisites
in this section.

\subsection{LLVM}

The Low Level Virtual Machine (LLVM) is an open source project that
was initially intended to provide support for a Static Single
Assignment (SSA) compiler that is capable of statically or dynamically
compiling any programming language \cite{llvm.org}.

Listing \ref{lst:llvm-example_hello0.ll} shows
a simple LLVM hello world program as an example of
what LLVM IR Assembly language looks like.

\lstinputlisting[
  float=*htb,
  language=llvm,
  label=lst:llvm-example_hello0.ll,
  caption={LLVM Assembly - Hello World Example \cite{lattner-llvmlangref}}
]{../code/llvm-examples/hello0.ll}

The LLVM IR language exists in three grammatically equivalent forms:
as an in-memory data structure, as a human readable ``assembly''
language, and as an file-oriented bitcode (.bc) \cite{lattner-llvmlangref}.
Converting between these three forms is handled via the various tools
in the LLVM tool chain. Listing \ref{lst:llvm-example_hello0.ll} is an
example of the human-readable form most commonly presented in this
paper.

LLVM requires SSA form. Prior to converting to LLVM IR, we must first
convert to SSA. SSA form is discussed in the next section.

\subsection{Static Single Assignment Form}

A program is in SSA form when its variables are assigned exactly once
in the program \cite{gcc-gnu.org}. Most programs are not written in an
SSA form, but can be converted to SSA form by giving a variable a new
name every time it is assigned to, and replacing all uses of the
variable in right-hand side expressions with the most recent version
of the variable \cite{brandis-mossenbock}. In a linear code segment,
this is a fairly straightforward transformation. When branching and
polymorphism are added, however, it becomes a more complex issue, as
seen below:

\begin{verbatim}
if input():
  x = 3
else:
  x = 3.145
print x
\end{verbatim}

This piece of code contains branching, so x is being assigned to
multiple times. In addition, x could be an integer or a floating point
number. To convert to SSA in this situation, compilers can add a
\emph{phi} ($\phi$) node to select the proper version of x to use as
the current version. See below:

\begin{verbatim}
if input():
  x_0 = 3
else:
  x_1 = 3.145
x_2 = PHI<x_1, x_2>
print x_2
\end{verbatim}

The $\phi$ function (node) serves to pick the branch that was used at
runtime, and return that version of x.

Fortunately, LLVM provides a \emph{phi} node in its assembly language
specification \cite{lattner-llvmlangref}. It addresses the multiple
assignment problems that result from control flow. The syntax is

\begin{verbatim}
<result> = phi <ty> [<val0>, <label0>]...
\end{verbatim} 

where the ``ty'' field is the incoming type of the data to be chosen
from. However, this indicates that the $\phi$ node can not handle
explicit polymorphism. Fortunately, we have already packaged all of
our data types into one unique type: a pyobj. All values passed to the
block must be first class values, so a pointer to a pyobj will be the
only option available to handle polymorphism. The type field is
followed by a list of pairs, one for each predecessor block of code in
the current block, and the $\phi$ function will use the value
corresponding to the block actually executed.

\section{Approach}

Prior to actually modifying our compiler, we spent extensive time
manually experimenting with LLVM Assembly. This included manually
``compiling'' several of our test programs to LLVM assembly, and then
compiling and running the LLVM Assembly we produced, in order to
verify our understanding of the language. This process both increased
our understanding of the LLVM language, and allowed us to prove out the
updated build and test infrastructure for LLVM files.

After familiarizing ourselves with LLVM, we proceeded to modify our
compiler via the following development steps:

\begin{packed_enum}
\item Fixed bugs in existing compiler until we passed all valid student
  and instructor provided p3 test cases.
\item Re-factored existing compiler to better handle common visitor
  functions, support a modular parser-interface, and reduce code
  complexity.
\item Added an additional compilation pass that translates the flattened
  AST into SSA form.
\item Added an alternate instruction selection pass that generates LLVM
  assembly instead of x86 assembly.
\item Added the necessary top-level compiler control handling to switch
  between LLVM and x86 generation based on an input parameter.
\item Modified the existing Makefile, build, and test systems to handle
  both x86 and LLVM code generation. Converted test infrastructure to
  performing 3-way compares between native Python execution, x86
  execution, and LLVM execution.
\item Confirmed behavior of LLVM generated code matches that of the
  native Python interpreter, as well as that of the x86 generated
  code.
\item Identified and fixed bugs as necessary.
\end{packed_enum}

\section{Design}
\label{sec:design}

Our compiler design begins with the basic compiler design presented in
\cite{siek-chang} for the Python ``P3'' language subset.  We then
proceeded to re-factor this design to better exploit code reuse,
remove deprecated interfaces, support multiple target types, and
automatically catch a range of implementation errors. We plan on
keeping the re-factored design common for all compilation targets
through the end of the flatten pass.

The major changes happen after flatten in the instruction selection
and related passes. A significant difference between our current x86
compiler and our LLVM compiler is that the LLVM compiler requires the
AST to be in SSA form. In addition, LLVM uses variable names, not
pre-defined registers, in its instructions. As such, the LLVM
compilation requires an additional pass to convert to SSA form, but
can forgo the pass that performs register allocation.  An alternate
version of the instruction selection pass has also been added in
support of to the LLVM Assembly format.

\subsection{Module Flow}
\label{sec:ModuleFlow}

\begin{figure*}[htb]
   \centering
   \includegraphics[width=.90\textwidth]{./include/CompilerFlow.pdf}
   \caption{Compiler Data Flow}
   \label{fig:CompilerFlow}
\end{figure*}

Our compiler employs a modular design to maximize code reuse between
various target languages.  Our compiler stages up through flatten are
designed to be target-agnostic. It is only the post-flatten stages
that differ based on the compilation target (x86 or LLVM). Figure
\ref{fig:CompilerFlow} shows our modular flow through our compiler and
the various data structures present between each stage.

The new compiler stages necessary for LLVM targeted compilations are
the ``SSA'' stage, the ``Propagate'' stage, and the ``LLVM Instruction
Selection'' stage. The purpose of each stage is briefly discussed
below.

\begin{packed_desc}
\item[SSA Stage] \hfill \\
  The Static Single Assignment (SSA) stage converts
  the multi-assignment Python AST into a Static Single Assignment
  Python AST. It replaces variable assignments to ensure each variable
  is only ever written once, and also sets up the necessary Phi operations
  associated with branching nodes (if, while, etc).
  This process is discussed further in Section \ref{sec:stage-SSA}.
\item[Propagate Stage] \hfill \\
  The propagate stage is essentially a
  lightweight constant propagation stage. It's goal is to eliminate
  all direct assignments (i.e. \texttt{|x = y|}) in favor of propagating
  the right hand side of such assignments into the actual operation in
  which they are used (i.e. \texttt{|x = y; print(x)|} $\rightarrow$
  \texttt{|print(y)|}). Since the code is already in SSA form, this
  process involves a rather simple search and substitution algorithm
  This process is discussed further in Section \ref{sec:stage-Propagate}.
\item[LLVM Instruction Selection] \hfill \\
  The LLVM Instruction Selection stage
  converts the Python AST into an LLVM IR (assembly) AST. The biggest
  challenge in this stage is converting the multi-branches Python AST
  into the linear list of code ``blocks'' that LLVM IR requires. This
  process is discussed further in Section
  \ref{sec:stage-LLVMInstructionSelection}.
\end{packed_desc}

We have also created a new initial compiler pass that converts the AST
nodes from whatever format a given parser uses to a uniform set of
internal AST nodes used throughout the rest of the compiler. This
allows us to switch parsing infrastructures without needing to change
the core compiler code. We have leveraged this capability to move away
from the deprecated Python compiler package used for the course
assignments thus far in favor of the built-in AST and parsing
infrastructure inherent in Python 2.7+.

\subsubsection{SSA}
\label{sec:stage-SSA}

LLVM also requires Static Single Assignment form, meaning that each
variable is assigned to exactly once.  We convert programs into SSA
form during compilation (only when compiled to SSA --- our x86
compiler does not utilize the SSA conversion module), a process which
occurs after flattening and immediately before LLVM instruction
selection (as shown in Figure \ref{fig:CompilerFlow}).  This
conversion process takes a single pass over the program, and converts
it as follows:

\begin{itemize}
\item When an assignment statement (to a variable) is encountered, the
  converter increments the ``version number'' of the variable (or
  initializes it to $0$ if the variable has not been previously
  assigned to). The variable is then renamed to record this version
  number, and the current version number of the variable is recorded
  in a dictionary.
\item When a variable name is encountered, it is replaced by the most
  recent version of the variable.
\item When an If statement is encountered, the true and false branches
  are scanned for their assigned variables, and a new attribute is
  added to the end of the statement, containing Phi nodes for the
  variables assigned within the If as follows:
  \begin{itemize}
  \item If a variable is assigned to in both branches, the Phi node
    contains the version from each branch.
  \item If a variable is assigned to in one branch but not the other,
    \textit{and} the variable was also assigned to before the If
    statement was entered, then the Phi node contains the new version
    in the branch it appeared in, and the old version in the other
    branch.
  \item If a variable is assigned to in one branch but not the other,
    \textit{and} the variable did not exist before the If
    statement was entered, no Phi node is created for it.
  \end{itemize}
\item When a While loop is encountered, its body is scanned for
  assigned variables. A new attribute is then added to the beginning
  of the statement, containing Phi nodes for each variable that is
  assigned to in the body and that also existed before the loop was
  entered.
\end{itemize}

This process ensures that each variable is assigned to only once while
maintaining the semantics of the program. At the moment, we do not use
any of the optimizations, such as those based on computing the
dominator tree of the program as described by Brandis and
M\"{o}ssenb\"{ock} \cite{brandis-mossenbock}, though we may implement such
optimizations in the future, especially if the conversion pass is
moved to an earlier point in the compilation.

\subsubsection{Propagate}
\label{sec:stage-Propagate}

To Do...

\subsubsection{LLVM Instruction Selection}
\label{sec:stage-LLVMInstructionSelection}

The LLVM instruction selection requires several more features to be
supported than were supported in the x86 pass. While LLVM is more
flexible in terms of compilation on multiple operating systems, its
intermediate representation is more stringent than x86. In order to
learn the nuances of the LLVM Intermediate Representation that we must
address in our compiler, we began converting our test programs
to LLVM IR by hand and compiling them. This revealed several new issues
that we addressed in our LLVM instruction selection.

For example, each instruction must keep track of the types of all
registers involved. Fortunately, our pyobj pointer system will make
keeping track of type much more straightforward, as all objects are of
one type: pointers to pyobj structures. The LLVM code can merely treat
this as generic pointers, leaving the C helper function to handle any
functionality that requires knowledge about what type of object to
which these pointers point.

Another issue is that all called functions that are defined in
external files must be declared at the beginning of any .ll (LLVM
Intermediate Representation) file that our compiler generates. This
necessitates our writing a preamble to place at the beginning of every
.ll file which contains the declarations for our runtime helper
functions.

One nuance is that expressions such as
\begin{verbatim}
%x = 5
\end{verbatim} 
are not allowed. Presumably, this is because LLVM is an SSA
representation, and one is essentially wasting an entire register on a
constant \cite{llvm-discussions}. The options available are to perform
constant propagation, or to declare each constant as an internal
constant, like so:
\begin{verbatim}
@V1 = constant i32 5
\end{verbatim}
Then, when the constant needs to be loaded from memory. This is
because @V1 is a pointer to the constant, not the constant itself
\cite{Regni}:
\begin{verbatim}
%x = load i32* @V1
\end{verbatim}

In our implementation, we intend to use the later approach, as we are
not focusing on constant propagation in this project. Although, the
fact that this is an SSA implementation would mean that all instances
of \%x could be replaced with the constant 5 using a simple
find-replace. We consider this option as a future optimization.

...To be continued...

\subsection{LLVM Build Process}

We have also implemented a method for compiling the C run-time helper
functions to LLVM bitcode using an LLVM front end C compiler, clang
\cite{clang.llvm.org}. We then link the helper function generated
bitcode to the bitcode generated from the .ll output from our
compiler. This gives us a bitcode file that we are capable of running
in the LLVM interpreter or fully compiling to an executable.  The
process for compiling is shown in Listing \ref{lst:compiling.sh}.

\lstinputlisting[
  float=*htb,
  language=sh,
  label=lst:compiling.sh,
  caption={Pseudo-script describing the LLVM build process}
]{./include/txt/compiling.sh}

\section{Results}

The full source code for our compiler is available at \cite{github-repo}.

...To be added when complete...

\section{Discussion}

...To be added when complete...

\section{Conclusion}

...To be added when complete...

\nocite{*}
\printbibliography

\end{document}
