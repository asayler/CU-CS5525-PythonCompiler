% CU CS5525
% Fall 2012
% Python Compiler
%
% proposal.tex
% Semester Project Proposal
%
% Repository:
%    https://github.com/asayler/CU-CS5525-PythonCompiler
%
% By :
%    Anne Gatchell
%       http://annegatchell.com/
%    Andy Sayler
%       http://www.andysayler.com
%    Michael (Mike) Vitousek
%       http://csel.cs.colorado.edu/~mivi2269/

\documentclass[11pt]{article}

\usepackage[text={6.5in, 9in}, centering]{geometry}
\usepackage{graphicx}
\usepackage{url}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{biblatex}
\usepackage{amssymb}
\bibliography{refs}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\lstset{
  language={},
  basicstyle=\footnotesize,
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=4,
  captionpos=b,
  breaklines=true,
  breakatwhitespace=false,
  frame=single,
  frameround=tttt
}

\lstdefinelanguage{llvm}{
  morecomment = [l]{;},
  morestring=[b]'', 
  sensitive = true,
  classoffset=0,
  morekeywords={
    define, declare, global, constant,
    internal, external, private,
    linkonce, linkonce_odr, weak, weak_odr, appending,
    common, extern_weak,
    thread_local, dllimport, dllexport,
    hidden, protected, default,
    except, deplibs,
    volatile, fastcc, coldcc, cc, ccc,
    x86_stdcallcc, x86_fastcallcc,
    ptx_kernel, ptx_device,
    signext, zeroext, inreg, sret, nounwind, noreturn,
    nocapture, byval, nest, readnone, readonly, noalias, uwtable,
    inlinehint, noinline, alwaysinline, optsize, ssp, sspreq,
    noredzone, noimplicitfloat, naked, alignstack,
    module, asm, align, tail, to,
    addrspace, section, alias, sideeffect, c, gc,
    target, datalayout, triple,
    blockaddress
  },
  classoffset=1,
  morekeywords={
    fadd, sub, fsub, mul, fmul,
    sdiv, udiv, fdiv, srem, urem, frem,
    and, or, xor,
    icmp, fcmp,
    eq, ne, ugt, uge, ult, ule, sgt, sge, slt, sle,
    oeq, ogt, oge, olt, ole, one, ord, ueq, ugt, uge,
    ult, ule, une, uno,
    nuw, nsw, exact, inbounds,
    phi, call, select, shl, lshr, ashr, va_arg,
    trunc, zext, sext,
    fptrunc, fpext, fptoui, fptosi, uitofp, sitofp,
    ptrtoint, inttoptr, bitcast,
    ret, br, indirectbr, switch, invoke, unwind, unreachable,
    malloc, alloca, free, load, store, getelementptr,
    extractelement, insertelement, shufflevector,
    extractvalue, insertvalue,
  },
  alsoletter={\%},
  keywordsprefix={\%},
}

\newenvironment{packed_enum}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}

\newenvironment{packed_item}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\begin{document}

\title{
  Building a LLVM Python Compiler
}

\author{
  Anne Gatchell    \\ \texttt{anne.gatchell@colorado.edu} \and
  Andy Sayler      \\ \texttt{andrew.sayler@colorado.edu} \and
  Michael Vitousek \\ \texttt{michael.vitousek@colorado.edu}
}

\date{\today}

\maketitle

\begin{abstract}

We discuss the expansion of our P3 compiler to target LLVM intermediate
language assembly code. This involves the converting our intermediate
AST to SSA form as well as replacing the instruction selection
components of the existing compiler. We compare the performance and
flexibility of directly targeted x86 code vs LLVM targeted code.

\end{abstract}

\section{Problem Statement}

While the existing HW6, p3-compliant compiler supports 32-bit, x86
code generation, it does not support generating code for the variety
of non-x86 architectures and assembly languages common today (x64,
ARM, etc). While we could remedy this deficiency by adding additional
native code generation for non-x86 architectures directly to our
compiler, this approach would duplicate a wide range of existing
effort and would require continued maintenance to support new
architectures and assembly languages as they arise.

Instead, we aim to leverage the existing work done by the LLVM project
\cite{llvm.org} to convert our HW6 compiler from an x86-targeted
compiler to an LLVM-targeted compiler. This will not only be efficient
from a mantainance standpoint, but it will also be a useful
introduction to a commonly used intermediate language. We will
maintain the current x86 targeting and add LLVM
Assembly\cite{lattner-llvmlangref} as an additional targeting
option. In this way, we will be able to compare our natively generated
x86 code with the LLVM-assembler generated x86 code. We will also be
able to experiment with compiling our LLVM byte-code files to assembly
languages other than x86 such as x64 and ARM.

LLVM is quickly becoming the de facto standard target for most modern
compilers for high level languages.  It provides multi-platform
support, multi-runtype support (compiled, interpreted, JIT compiled,
etc), and access to a range of existing optimization tools and
techniques. Through this project, we hope to become familiar with the
LLVM Assembly Language and LLVM system architecture while gaining
insight into the benefits of building an LLVM-targeted compiler.

\section{Background}

The primary change to our existing compiler code base is the addition
of an LLVM output target option.

\subsection{LLVM}

The Low Level Virtual Machine (LLVM) is an open source project that
was initially intended to provide support for a Static Single
Assignment (SSA) compiler that is capable of staticly or dynamicly
compiling any programming language \cite{llvm.org}.

Listing \ref{lst:llvm-example_hell0.ll} shows
a simple LLVM hello world program as an example of
what LLVM Assembly language looks like.

\lstinputlisting[
  language=llvm,
  label=lst:llvm-example_hell0.ll,
  caption={LLVM Assembly - Hello World Example \cite{lattner-llvmlangref}}
]{../code/llvm-examples/hello0.ll}

\subsection{Static Single Assignment (SSA) Form}

A program is in SSA form when its variables are assigned exactly once
in the program \cite{gcc-gnu.org}. Most programs are not written in an
SSA form, but can be converted to SSA form by giving a variable a new
name every time it is assigned to, and replacing all uses of the
variable in right-hand side expressions with the most recent version
of the variable \cite{brandis-mossenbock}. In a linear code segment,
this is a fairly straightforward transformation. When branching and
polymorphism are added, however, it becomes a more complex issue, as
seen below:

\begin{verbatim}
if input():
  x = 3
else:
  x = 3.145
print x
\end{verbatim}

This piece of code contains branching, so x is being assigned to
multiple times. In addition, x could be an integer or a floating point
number. To convert to SSA in this situation, compilers can add a
\emph{phi} ($\phi$)node to select the proper version of x to use as
the current version. See below:

\begin{verbatim}
if input():
  x_0 = 3
else:
  x_1 = 3.145
x_2 = PHI<x_1, x_2>
print x_2
\end{verbatim}

The $\phi$ function (node) serves to pick the branch that was used at
runtime, and return that version of x.

Fortunately, LLVM provides a \emph{phi} node in its assembly language
specification \cite{llvm.org}. It addresses the multiple assignment
problems that result from control flow. The syntax is

\begin{verbatim}
<result> = phi <ty> [ <val0>, <label0>], ...
\end{verbatim} 

where the ty field is the incoming type of the data to be chosen
from. This indicates that the PHI node can not handle explicit
polymorphism. Fortunately, we have already packaged all of our data
types into one unique type: a pyobj. All values passed to the block
must be first class values, so a pointer to a pyobj will be the only
option avaiable to handle polymorphism. The type field is followed by
a list of pairs, one for each predecessor block of code in the current
block, and the \emph{phi} function will use the value corresponding to
the block actually executed.

\section{Approach}

Our primary goal is to add support for compilation to the LLVM
assembly language to our existing p3 compiler. To achieve this goal,
we will advance through the following development steps:


% Note: this section should be pruned to only reflect completed tasks
% and switched to the past tense.
\begin{packed_enum}
\item Fix bugs in existing p3 compiler until we pass all valid student
  and instructor provided p3 test cases. This step has been completed.
\item Re-factor existing p3 compiler to better handle common visitor
  functions, support a modular parser-interface, and reduce code
  complexity. This step is \emph{in progress and near complete}.
\item Become familiar with LLVM Assembly language by manually
  translating a few basic Python programs to LLVM and ensuring that
  when run, the compiled and linked output matches the behavior of the
  Python interpreter. This step is \emph{in progress}.
\item Add an additional compilation pass that translates the flattened
  AST into SSA form. This step has \emph{not been started}.
\item Add an alternate instruction selection pass that generates LLVM
  assembly instead of x86 assembly. This step has \emph{not been
    started}.
\item Add the necessary top-level compiler control handling to switch
  between LLVM and x86 generation based on an input parameter. This
  step has \emph{not been started}.
\item Modify the existing Makefile, build, and test systems to handle
  both x86 and LLVM code generation. Convert test infrastructure to
  performing 3-way compares between native Python execution, x86
  execution, and LLVM execution. This step has \emph{not been
    started}.
\item Confirm behavior of LLVM generated code matches that of the
  native Python interpreter, as well as that of the x86 generated
  code. Identify and fix bugs as necessary. This step has \emph{not
    been started}.
\end{packed_enum}

Should we have additional time, we also intend to pursue one or more
of the following extensions to the core LLVM implementation:

\begin{packed_item}
\item Compare both the compile-time and the run-time performance of
  targeting LLVM vs targeting native x86. Compare run-time performance
  of both against that of the native Python interpreter.
\item Experiment with compiling the C run-time helper function to LLVM
  via clang\cite{clang.llvm.org}
  and linking the resulting LLVM byte-code and the output
  from our compiler natively. This would allow us to run the compiler
  in the LLVM interpreter and take advantage of the LLVM JIT features.
\item Compare the run-time performance of compiled LLVM code vs
  interpreted LLVM code. This would require completing the previous
  extension as well. Compare run-time performance
  of both against the native Python interpreter.
\item Test our compiler on x64 and ARM based systems to verify and
  observe the portable, multi-platform benefits of LLVM Assembly.
\item Take advantage of LLVM type system and decorator extensions to
  produce more optimized code than our initial revision is capable of.
  Compare the performance gains vs the initial, ``naively'' generated
  LLVM code.
\item Add support for the Python 3 p3-equivalent language subset.
\end{packed_item}

\section{Design}

% This section needs re-factored to the past tense.
We have been working on re-factoring our HW6, p3 compiler, and we plan
on keeping the re-factored design through the end of the flatten
pass. The major changes will happen after flatten in the instruction
selection and related passes A significant difference between our
current x86 compiler and our planned LLVM compiler is that the LLVM
compiler uses variable names, not pre-defined registers, in its
instructions; much like our current p3 compiler does at the state
prior to register allocation. Instruction selection and the
intermediate nodes will need to be altered to lend themselves to the
LLVM Assembly format.

\subsection{SSA conversion}

LLVM also requires Static Single Assignment form, meaning that each
variable is assigned to exactly once.  We convert programs into SSA
form during compilation (only when compiled to SSA --- our x86
compiler does not utilize SSA at the moment), a process which occurs
after flattening and immediately before LLVM instruction selection, as
shown in Figure \ref{fig:CompilerFlow}.  This conversion process takes
a single pass over the program, and converts it as follows:

\begin{itemize}
\item When an assignment statement (to a variable) is encountered, the
  converter increments the ``version number'' of the variable (or
  initializes it to $0$ if the variable has not been previously
  assigned to). The variable is then renamed to record this version
  number, and the current version number of the variable is recorded
  in a dictionary.
\item When a variable name is encountered, it is replaced by the most
  recent version of the variable.
\item When an If statement is encountered, the true and false branches
  are scanned for their assigned variables, and a new attribute is
  added to the end of the statement, containing Phi nodes for the
  variables assigned within the If as follows:
  \begin{itemize}
  \item If a variable is assigned to in both branches, the Phi node
    contains the version from each branch.
  \item If a variable is assigned to in one branch but not the other,
    \textit{and} the variable was also assigned to before the If
    statement was entered, then the Phi node contains the new version
    in the branch it appeared in, and the old version in the other
    branch.
  \item If a variable is assigned to in one branch but not the other,
    \textit{and} the variable did not exist before the If
    statement was entered, no Phi node is created for it.
  \end{itemize}
\item When a While loop is encountered, its body is scanned for
  assigned variables. A new attribute is then added to the beginning
  of the statement, containing Phi nodes for each variable that is
  assigned to in the body and that also existed before the loop was
  entered.
\end{itemize}

This process ensures that each variable is assigned to only once while
maintaining the semantics of the program. At the moment, we do not use
any of the optimizations, such as those based on computing the
dominator tree of the program as described by Brandis and
M\"{o}ssenb\"{ock} \cite{brandis-mossenbock}, though we may implement such
optimizations in the future, especially if the conversion pass is
moved to an earlier point in the compilation.

%%% END OF SSA SECTION %%%

\begin{figure}[htb]
  \centering
  \includegraphics[width=.90\textwidth]{include/CompilerFlow.pdf}
  \caption{Compiler Data Flow}
  \label{fig:CompilerFlow}
\end{figure}

Our compiler will employ a modular design to maximize code reuse
between various target languages.  We intend for our compiler passes
up through flatten to be target-agnostic. It is only the post-flatten
passes that will differ based on the compilation target (x86 or
LLVM). We have also created a new initial compiler pass that converts
the AST nodes from whatever format a given parser uses to a uniform
set of internal AST nodes used throughout the rest of the
compiler. This allows us to switch parsing infrastructures without
needing to change the core compiler code. We are in the process of
moving away from the deprecated Python compiler package used for the
course assignments thus far in favor of the built-in AST and parsing
infrastructure inherent in Python 2.7+. We are also considering
updating our compiler to support the Python3 p3 equivalent.

Since LLVM is a typed representation, we will need to incorporate type
information into our representation. Initially, we intend to keep the
use of explicit LLVM types to a minimum to simplify implementation and
best mimic the behavior of the native x86 compiler. Should we have
time, the LLVM typing system might allow us to take a more nuanced
typing approach, and in doing so, take advantage of some of the LLVM
type-based optimizations. This may also necessitate rewriting the
run-time C library to better meld with LLVM's capabilities.

\section{Results}

\section{Discussion}

\section{Conclusion}

\nocite{*}
\printbibliography

\end{document}
